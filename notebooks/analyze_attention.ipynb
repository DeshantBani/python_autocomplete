{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from labml import experiment, logger, lab\n",
    "from labml_helpers.module import Module\n",
    "from labml.analytics import ModelProbe\n",
    "from labml.logger import Text, Style, inspect\n",
    "from labml.utils.pytorch import get_modules\n",
    "from labml.utils.cache import cache\n",
    "from labml_helpers.datasets.text import TextDataset\n",
    "\n",
    "from python_autocomplete.train import Configs\n",
    "from python_autocomplete.evaluate import Predictor\n",
    "from python_autocomplete.evaluate.beam_search import NextWordPredictionComplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model from a training run. For this demo I'm loading from a run I trained at home.\n",
    "\n",
    "[![View Run](https://img.shields.io/badge/labml-experiment-brightgreen)](https://web.lab-ml.com/run?uuid=39b03a1e454011ebbaff2b26e3148b3d)\n",
    "\n",
    "If you have a locally trained model load it directly with:\n",
    "\n",
    "```python\n",
    "run_uuid = 'RUN_UUID'\n",
    "checkpoint = None # Get latest checkpoint\n",
    "```\n",
    "\n",
    "`load_bundle` will download an archive with a saved checkpoint (pretrained model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #208FFB\">Run a6cff3706ec411ebadd9bf753b33bae6 exists</span>\n",
       "<span style=\"color: #208FFB\">Checkpoint 702925824 exists</span>\n",
       "Extract bundle<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,597.77ms</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run_uuid = 'a6cff3706ec411ebadd9bf753b33bae6'\n",
    "# checkpoint = None\n",
    "\n",
    "run_uuid, checkpoint = experiment.load_bundle(\n",
    "    lab.get_path() / 'saved_checkpoint.tar.gz',\n",
    "    url='https://github.com/lab-ml/python_autocomplete/releases/download/0.0.5/bundle.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize `Configs` object defined in [`train.py`](https://github.com/lab-ml/python_autocomplete/blob/master/python_autocomplete/train.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = Configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new experiment in evaluation mode. In evaluation mode a new training run is not created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load custom configurations/hyper-parameters used in the training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 32,\n",
       " 'is_token_by_token': True,\n",
       " 'mem_len': 256,\n",
       " 'model': 'transformer_xl_model',\n",
       " 'n_layers': 6,\n",
       " 'optimizer.learning_rate': 0.000125,\n",
       " 'optimizer.optimizer': 'AdamW',\n",
       " 'state_updater': 'transformer_memory',\n",
       " 'text.batch_size': 12,\n",
       " 'text.is_shuffle': False,\n",
       " 'text.seq_len': 256,\n",
       " 'text.tokenizer': 'bpe'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_conf = experiment.load_configs(run_uuid)\n",
    "custom_conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the custom configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_conf['device.use_cuda'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.configs(conf, custom_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set models for saving and loading. This will load `conf.model` from the specified run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Prepare model...\n",
       "  Prepare n_tokens...\n",
       "    Prepare tokenizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t5.65ms</span>\n",
       "  Prepare n_tokens<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10.63ms</span>\n",
       "  Prepare transformer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t2.79ms</span>\n",
       "  Prepare ffn<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1.35ms</span>\n",
       "  Prepare device...\n",
       "    Prepare device_info<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t2.72ms</span>\n",
       "  Prepare device<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t5.01ms</span>\n",
       "Prepare model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t188.53ms</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.add_pytorch_models({'model': conf.model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify which run to load from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.load(run_uuid, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Selected <span style=\"color: #60C6C8\">experiment</span> = <strong>source_code</strong> <span style=\"color: #60C6C8\">run</span> = <strong>a6cff3706ec411ebadd9bf753b33bae6</strong> <span style=\"color: #60C6C8\">checkpoint</span> = <strong>702,925,824</strong>\n",
       "Loading checkpoint<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t367.00ms</span>\n",
       "\n",
       "<strong><span style=\"text-decoration: underline\">Notebook Experiment</span></strong>: <span style=\"color: #208FFB\">9ffa0982782311ecb21facde48001122</span>\n",
       "[clean]: <strong><span style=\"color: #DDB62B\">\"ðŸ”¬ probe attentions\"</span></strong>\n",
       "\tloaded from: <span style=\"color: #D160C4\">a6cff3706ec411ebadd9bf753b33bae6</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<labml.internal.experiment.watcher.ExperimentWatcher at 0x7f93f10eaf90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the `Predictor` defined in [`evaluate.py`](https://github.com/lab-ml/python_autocomplete/blob/master/python_autocomplete/evaluate.py).\n",
    "\n",
    "We load `stoi` and `itos` from cache, so that we don't have to read the dataset to generate them. `stoi` is the map for character to an integer index and `itos` is the map of integer to character map. These indexes are used in the model embeddings for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\">Prepare state_updater<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t4.11ms</span>\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = Predictor(conf.model, conf.text.tokenizer,\n",
    "              state_updater=conf.state_updater,\n",
    "              is_token_by_token=conf.is_token_by_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = conf.model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup probing to extract attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "probe = ModelProbe(conf.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A python prompt to test completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from labml_nn.lstm import LSTM\n",
    "from python_autocomplete.models import AutoregressiveModel\n",
    "\n",
    "\n",
    "class LstmModel(AutoregressiveModel):\n",
    "    def __init__(self, *,\n",
    "                 n_tokens: int,\n",
    "                 embedding_size: int,\n",
    "                 hidden_size: int,\n",
    "                 n_layers: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(n_tokens, embedding_size)\n",
    "        self.lstm = LSTM(input_size=embedding_size,\n",
    "                         hidden_size=hidden_size,\n",
    "                         n_layers=n_layers)\n",
    "        self.fc = nn.Linear(hidden_size, n_tokens)\n",
    "\n",
    "    def __call__(self, x: torch.Tensor, state: Optional[Tuple[torch.Tensor, torch.Tensor]]):\n",
    "        # shape of x is [seq, batch, feat]\n",
    "        x = self.embedding(x)\n",
    "        out, (hn, cn) = self.lstm(x, state)\n",
    "        logits = self.fc(out)\n",
    "\n",
    "        return logits, (hn, cn)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a token. `get_token` predicts character by character greedily (no beam search) until it find and end of token character (non alpha-numeric character)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripped, prompt = p.rstrip(PROMPT)\n",
    "rest = PROMPT[len(stripped):]\n",
    "prediction_complete = NextWordPredictionComplete(rest, 5)\n",
    "prompt = torch.tensor(prompt, dtype=torch.long).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets analyze attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">  0: </span><span style=\"color: #C5C1B4\">\"</span><strong>from</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  1: </span><span style=\"color: #C5C1B4\">\"</span><strong> </strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  2: </span><span style=\"color: #C5C1B4\">\"</span><strong>ty</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  3: </span><span style=\"color: #C5C1B4\">\"</span><strong>p</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  4: </span><span style=\"color: #C5C1B4\">\"</span><strong>ing</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  5: </span><span style=\"color: #C5C1B4\">\"</span><strong> </strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  6: </span><span style=\"color: #C5C1B4\">\"</span><strong>import</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  7: </span><span style=\"color: #C5C1B4\">\"</span><strong> </strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  8: </span><span style=\"color: #C5C1B4\">\"</span><strong>Opt</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">  9: </span><span style=\"color: #C5C1B4\">\"</span><strong>ional</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #208FFB\">...</span>\n",
       "Total <span style=\"color: #208FFB\">279</span> item(s)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = [p.tokenizer.itos[i[0]] for i in prompt]\n",
    "inspect(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run the transformer XL model without cached memory to get the full attention matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #C5C1B4\">dtype: </span><span style=\"color: #208FFB\">torch.float32</span>\n",
       "<span style=\"color: #C5C1B4\">shape: </span><strong>[1, 1097]</strong>\n",
       "<span style=\"color: #C5C1B4\">min: </span><span style=\"color: #208FFB\">0.000000</span> <span style=\"color: #C5C1B4\">max: </span><span style=\"color: #208FFB\">0.611870</span> <span style=\"color: #C5C1B4\">mean: </span><span style=\"color: #208FFB\">0.000912</span> <span style=\"color: #C5C1B4\">std: </span><span style=\"color: #208FFB\">0.020015</span>\n",
       "<strong></strong><span style=\"color: #C5C1B4\">[</span><strong></strong>\n",
       "<strong></strong><strong> </strong><span style=\"color: #C5C1B4\">[</span><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000010</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong> </strong><span style=\"color: #C5C1B4\">]</span><strong></strong>\n",
       "<strong></strong><strong></strong><span style=\"color: #C5C1B4\">]</span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inspect(p._get_predictions(prompt, None)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We capture the outputs after the [attention softmax](https://nn.labml.ai/transformers/mha.html#section-34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">0: </span><span style=\"color: #C5C1B4\">\"</span><strong>transformer.layers.0.self_attn.softmax</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">1: </span><span style=\"color: #C5C1B4\">\"</span><strong>transformer.layers.1.self_attn.softmax</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">2: </span><span style=\"color: #C5C1B4\">\"</span><strong>transformer.layers.2.self_attn.softmax</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">3: </span><span style=\"color: #C5C1B4\">\"</span><strong>transformer.layers.3.self_attn.softmax</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">4: </span><span style=\"color: #C5C1B4\">\"</span><strong>transformer.layers.4.self_attn.softmax</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "<span style=\"color: #60C6C8\">5: </span><span style=\"color: #C5C1B4\">\"</span><strong>transformer.layers.5.self_attn.softmax</strong><span style=\"color: #C5C1B4\">\"</span>\n",
       "Total <span style=\"color: #208FFB\">6</span> item(s)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inspect(probe.forward_output['*softmax*'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = probe.forward_output['*softmax*'].get_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attentions have shape `[source, destination, batch, heads]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">0: </span><strong>279</strong>\n",
       "<span style=\"color: #60C6C8\">1: </span><strong>279</strong>\n",
       "<span style=\"color: #60C6C8\">2: </span><strong>1</strong>\n",
       "<span style=\"color: #60C6C8\">3: </span><strong>8</strong>\n",
       "Total <span style=\"color: #208FFB\">4</span> item(s)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inspect(attn[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_maps = torch.stack([a.permute(2, 3, 0, 1)[0] for a in attn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"overflow-x: scroll;\"><span style=\"color: #C5C1B4\">dtype: </span><span style=\"color: #208FFB\">torch.float32</span>\n",
       "<span style=\"color: #C5C1B4\">shape: </span><strong>[6, 8, 279, 279]</strong>\n",
       "<span style=\"color: #C5C1B4\">min: </span><span style=\"color: #208FFB\">0.000000</span> <span style=\"color: #C5C1B4\">max: </span><span style=\"color: #208FFB\">1.000000</span> <span style=\"color: #C5C1B4\">mean: </span><span style=\"color: #208FFB\">0.003584</span> <span style=\"color: #C5C1B4\">std: </span><span style=\"color: #208FFB\">0.026890</span>\n",
       "<strong></strong><span style=\"color: #C5C1B4\">[</span><strong></strong>\n",
       "<strong></strong><strong> </strong><span style=\"color: #C5C1B4\">[</span><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">[</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>1.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.993492</strong><strong>, </strong><strong>0.006508</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.991854</strong><strong>, </strong><strong>0.008065</strong><strong>, </strong><strong>0.000081</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.003070</strong><strong>, </strong><strong>0.000385</strong><strong>, </strong><strong>0.003941</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000002</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">[</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>1.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.996190</strong><strong>, </strong><strong>0.003810</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.761333</strong><strong>, </strong><strong>0.231494</strong><strong>, </strong><strong>0.007174</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.007664</strong><strong>, </strong><strong>0.000290</strong><strong>, </strong><strong>0.000628</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000009</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">[</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>1.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.999664</strong><strong>, </strong><strong>0.000336</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.780615</strong><strong>, </strong><strong>0.219290</strong><strong>, </strong><strong>0.000096</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.001629</strong><strong>, </strong><strong>0.000160</strong><strong>, </strong><strong>0.000875</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000001</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">[</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>1.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.999970</strong><strong>, </strong><strong>0.000030</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.349430</strong><strong>, </strong><strong>0.616987</strong><strong>, </strong><strong>0.033583</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.000142</strong><strong>, </strong><strong>0.000123</strong><strong>, </strong><strong>0.000777</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000005</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong></strong>\n",
       "<strong></strong><strong> </strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong>\n",
       "<strong></strong><strong> </strong><span style=\"color: #C5C1B4\">[</span><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">[</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>1.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.999963</strong><strong>, </strong><strong>0.000037</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.893664</strong><strong>, </strong><strong>0.099487</strong><strong>, </strong><strong>0.006848</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.000250</strong><strong>, </strong><strong>0.000073</strong><strong>, </strong><strong>0.000148</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000001</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong>\n",
       "<strong></strong><strong>  </strong><span style=\"color: #C5C1B4\">[</span><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>1.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.999436</strong><strong>, </strong><strong>0.000564</strong><strong>, </strong><strong>0.000000</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><strong></strong><span style=\"color: #C5C1B4\">]</span><strong>, </strong><strong></strong><strong></strong><span style=\"color: #C5C1B4\">[</span><strong>0.733821</strong><strong>, </strong><strong>0.216545</strong><strong>, </strong><strong>0.049634</strong><strong>, </strong><span style=\"color: #C5C1B4\">...</span><strong>, </strong><strong>0.000000</strong><span style=\"color: #DDB62B\"> ... </span></pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inspect(attn_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save( attn_maps, 'attentions.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokens.json', 'w') as f:\n",
    "    f.write(json.dumps({'src': tokens, 'dst': tokens}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
