{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "labml autocomplete",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TGiFpndux7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c7028d-bdb4-45b1-d3a1-15d6d8d50104"
      },
      "source": [
        "# %%capture\n",
        "!pip install labml labml_nn labml_helpers labml_python_autocomplete"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting labml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/89/efba2bf65f6e49ba7ed1b6e60bf95689d155d41ccf458a5d016b9c9607d9/labml-0.4.81-py3-none-any.whl (92kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.5MB/s \n",
            "\u001b[?25hCollecting labml_nn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/7c/eac11034094a25e2b43519bebd84be44e60421bfd3a9e3ee2c3afad0d7de/labml_nn-0.4.74-py3-none-any.whl (93kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.8MB/s \n",
            "\u001b[?25hCollecting labml_helpers\n",
            "  Downloading https://files.pythonhosted.org/packages/51/ff/8b421289bd68c480c44179107b6d2cacba235a0ccee6f8bce4a89dba4538/labml_helpers-0.4.71-py3-none-any.whl\n",
            "Collecting labml_python_autocomplete\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/7d/257f272350fecc4da62e5d3d19b37a5202a8166bdf7337dac1eb6cc6c770/labml_python_autocomplete-0.0.3-py3-none-any.whl\n",
            "Collecting pyyaml>=5.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 50.3MB/s \n",
            "\u001b[?25hCollecting gitpython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from labml) (1.19.4)\n",
            "Collecting einops\n",
            "  Downloading https://files.pythonhosted.org/packages/5d/a0/9935e030634bf60ecd572c775f64ace82ceddf2f504a5fd3902438f07090/einops-0.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from labml_nn) (1.7.0+cu101)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->labml_nn) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->labml_nn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->labml_nn) (3.7.4.3)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=0671b36fedde7d40f7d54cad93cf8ad8a0a436bc6e475e2ee43d792552d37460\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml, smmap, gitdb, gitpython, labml, einops, labml-helpers, labml-nn, labml-python-autocomplete\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed einops-0.3.0 gitdb-4.0.5 gitpython-3.1.11 labml-0.4.81 labml-helpers-0.4.71 labml-nn-0.4.74 labml-python-autocomplete-0.0.3 pyyaml-5.3.1 smmap-3.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A45AlnGKvWxQ"
      },
      "source": [
        "from python_autocomplete import create_dataset\n",
        "from labml.logger import inspect\n",
        "from labml import monit, lab\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJHF_qsvu5zz"
      },
      "source": [
        "create_dataset.create_folders()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LKEDKTI-Fes"
      },
      "source": [
        "Get the list of repositories from [Awesome-PyTorch-list](https://github.com/bharathgs/Awesome-pytorch-list/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WqEth0cOD8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "b94874d3-b826-40a3-a6f2-e095bd473302"
      },
      "source": [
        "create_dataset.get_awesome_pytorch_readme()\n",
        "repos = create_dataset.get_repos_from_readme('pytorch_awesome.md')\n",
        "inspect(repos)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">  0: </span><strong>('pytorch', 'text')</strong>\n",
              "<span style=\"color: #60C6C8\">  1: </span><strong>('IBM', 'pytorch-seq2seq')</strong>\n",
              "<span style=\"color: #60C6C8\">  2: </span><strong>('Sandeep42', 'anuvada')</strong>\n",
              "<span style=\"color: #60C6C8\">  3: </span><strong>('pytorch', 'audio')</strong>\n",
              "<span style=\"color: #60C6C8\">  4: </span><strong>('facebookresearch', 'loop')</strong>\n",
              "<span style=\"color: #60C6C8\">  5: </span><strong>('facebookresearch', 'fairseq-py')</strong>\n",
              "<span style=\"color: #60C6C8\">  6: </span><strong>('awni', 'speech')</strong>\n",
              "<span style=\"color: #60C6C8\">  7: </span><strong>('OpenNMT', 'OpenNMT-py')</strong>\n",
              "<span style=\"color: #60C6C8\">  8: </span><strong>('huggingface', 'neuralcoref')</strong>\n",
              "<span style=\"color: #60C6C8\">  9: </span><strong>('NVIDIA', 'sentiment-discovery')</strong>\n",
              "<span style=\"color: #208FFB\">...</span>\n",
              "Total <span style=\"color: #208FFB\">665</span> item(s)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUDE_6Ge90Lm"
      },
      "source": [
        "Download zip files. For demonstration we only use 10 repos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "sL0AOQZovkCU",
        "outputId": "5f17e2e1-2b7c-48d5-b02f-e2ad76452104"
      },
      "source": [
        "repos = repos[:10]\n",
        "for i, r in monit.enum(f\"Download {len(repos)} repos\", repos):\n",
        "    zip_file = create_dataset.download_repo(r[0], r[1], i)\n",
        "    extracted = create_dataset.extract_zip(zip_file)\n",
        "    create_dataset.remove_files(extracted, {'.py'})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">Download 10 repos...\n",
              "  000:  pytorch/text<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,535.90ms</span><strong>\t6,093KB</strong>\n",
              "  Extract pytorch_text<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t146.02ms</span>\n",
              "  001:  IBM/pytorch-seq2seq<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t367.95ms</span><strong>\t1,600KB</strong>\n",
              "  Extract IBM_pytorch-seq2seq<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t47.48ms</span>\n",
              "  002:  Sandeep42/anuvada<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t7,549.68ms</span><strong>\t54,064KB</strong>\n",
              "  Extract Sandeep42_anuvada<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t747.80ms</span>\n",
              "  003:  pytorch/audio<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t421.49ms</span><strong>\t3,546KB</strong>\n",
              "  Extract pytorch_audio<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t82.18ms</span>\n",
              "  004:  facebookresearch/loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t224.61ms</span><strong>\t135KB</strong>\n",
              "  Extract facebookresearch_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t9.74ms</span>\n",
              "  005:  facebookresearch/fairseq-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t199.84ms</span><strong>\t3,466KB</strong>\n",
              "  Extract facebookresearch_fairseq-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t127.95ms</span>\n",
              "  006:  awni/speech<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t186.59ms</span><strong>\t111KB</strong>\n",
              "  Extract awni_speech<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t13.80ms</span>\n",
              "  007:  OpenNMT/OpenNMT-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t5,502.44ms</span><strong>\t79,624KB</strong>\n",
              "  Extract OpenNMT_OpenNMT-py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t854.00ms</span>\n",
              "  008:  huggingface/neuralcoref<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t4,563.47ms</span><strong>\t68,382KB</strong>\n",
              "  Extract huggingface_neuralcoref<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t804.85ms</span>\n",
              "  009:  NVIDIA/sentiment-discovery<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10,959.53ms</span><strong>\t55,457KB</strong>\n",
              "  Extract NVIDIA_sentiment-discovery<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,358.32ms</span>\n",
              "Download 10 repos<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t35,878.54ms</span>\n",
              "</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "FqVq3acy4LYg",
        "outputId": "f09061d6-f839-4558-fa3c-84744f0f1b6b"
      },
      "source": [
        "source_files = create_dataset.get_python_files()\n",
        "np.random.shuffle(source_files)\n",
        "inspect(source_files)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\"><span style=\"color: #60C6C8\">   0: </span><strong>PythonFile(relative_path='examples/simultaneous_translation/eval/client.py', pro</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   1: </span><strong>PythonFile(relative_path='examples/wav2vec/libri_labels.py', project='facebookre</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   2: </span><strong>PythonFile(relative_path='onmt/bin/average_models.py', project='OpenNMT_OpenNMT-</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   3: </span><strong>PythonFile(relative_path='fairseq/tasks/__init__.py', project='facebookresearch_</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   4: </span><strong>PythonFile(relative_path='fairseq/modules/quantization/scalar/modules/qlinear.py</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   5: </span><strong>PythonFile(relative_path='data_utils/loaders.py', project='NVIDIA_sentiment-disc</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   6: </span><strong>PythonFile(relative_path='fairseq/data/audio/feature_transforms/utterance_cmvn.p</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   7: </span><strong>PythonFile(relative_path='fairseq/logging/progress_bar.py', project='facebookres</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   8: </span><strong>PythonFile(relative_path='models/classification_attention_rnn.py', project='Sand</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #60C6C8\">   9: </span><strong>PythonFile(relative_path='seq2seq/trainer/supervised_trainer.py', project='IBM_p</strong><span style=\"color: #DDB62B\"> ...</span>\n",
              "<span style=\"color: #208FFB\">...</span>\n",
              "Total <span style=\"color: #208FFB\">1024</span> item(s)</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "AURmsHE24XbX",
        "outputId": "4b3b9be7-4728-4f90-8889-0b8c7d8e832d"
      },
      "source": [
        "train_valid_split = int(len(source_files) * 0.9)\n",
        "create_dataset.concat_and_save(lab.get_data_path() / 'train.py', source_files[:train_valid_split])\n",
        "create_dataset.concat_and_save(lab.get_data_path() / 'valid.py', source_files[train_valid_split:])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">Write train.py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t1,071.21ms</span>\n",
              "Write valid.py<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t357.69ms</span>\n",
              "</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFGGXj7H33sX"
      },
      "source": [
        "from python_autocomplete.train import Configs\n",
        "from labml import experiment"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4vMS55SQkFd"
      },
      "source": [
        "conf = Configs()\n",
        "experiment.create(name=\"python_autocomplete\",\n",
        "                  comment='lstm model')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0NV9wo4Q6mb"
      },
      "source": [
        "Set configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsV-pjvo6hbq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "d67818e6-c441-4fb5-ac04-1099cfcde96a"
      },
      "source": [
        "experiment.configs(conf, {\n",
        "    'model': 'lstm_model',  # Model\n",
        "    'n_layers': 2,  # Number of layers\n",
        "    'batch_size': 64,  # Batch size\n",
        "    'epochs': 32,   # Number of epochs\n",
        "    'optimizer.optimizer': 'Adam',  # Optimizer\n",
        "    'optimizer.learning_rate': 2.5e-4,  # Learning rate\n",
        "    'device.cuda_device': 0,  # Device\n",
        "    'inner_iterations': 5  # Number of iterations within an epoch \n",
        "                           # (switches between training and validation)\n",
        "})"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\"></pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU-DcoCr39f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7b51d668-c898-4ec8-d353-e328a59d7cd8"
      },
      "source": [
        "experiment.add_pytorch_models({'model': conf.model})"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">Prepare model...\n",
              "  Prepare n_tokens...\n",
              "    Prepare text...\n",
              "      Prepare tokenizer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t6.41ms</span>\n",
              "      Load data<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t8.76ms</span>\n",
              "      Tokenize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t145.58ms</span>\n",
              "      Build vocabulary<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t143.89ms</span>\n",
              "    Prepare text<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t317.92ms</span>\n",
              "  Prepare n_tokens<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t328.08ms</span>\n",
              "  Prepare device...\n",
              "    Prepare device_info<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t69.23ms</span>\n",
              "  Prepare device<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t72.23ms</span>\n",
              "Prepare model<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t10,931.10ms</span>\n",
              "</pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "9C_nSTOnQveY",
        "outputId": "c0535ac6-44aa-4123-b465-1eee014add5a"
      },
      "source": [
        "# experiment.load('d5ba7f56d88911eaa6629b54a83956dc')\n",
        "with experiment.start():\n",
        "    conf.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"overflow-x: scroll;\">\n",
              "<strong><span style=\"text-decoration: underline\">python_autocomplete</span></strong>: <span style=\"color: #208FFB\">c2c051c643fc11ebb7420242ac1c0002</span>\n",
              "\t<strong><span style=\"color: #DDB62B\">lstm model</span></strong>\n",
              "\t[dirty]: <strong><span style=\"color: #DDB62B\">\"\"</span></strong>\n",
              "Initialize...\n",
              "  Prepare mode<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t7.00ms</span>\n",
              "Initialize<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t60.84ms</span>\n",
              "Prepare validator...\n",
              "  Prepare valid_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t119.45ms</span>\n",
              "Prepare validator<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t192.55ms</span>\n",
              "Prepare trainer...\n",
              "<span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span><span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\">LABML WARNING</span></strong></span>\n",
              "<span style=\"color: #DDB62B\"><strong><span style=\"text-decoration: underline\"></span></strong></span>LabML App Warning: <span style=\"color: #60C6C8\">empty_token: </span><strong>Please create a valid token at https://web.lab-ml.com.</strong>\n",
              "<strong>Click on the experiment link to monitor the experiment and add it to your experiments list.</strong><span style=\"color: #C5C1B4\"></span>\n",
              "<span style=\"color: #C5C1B4\">--------------------------------------------------</span>\n",
              "<span style=\"color: #208FFB\">Monitor experiment at </span><a href='https://web.lab-ml.com/run?run_uuid=c2c051c643fc11ebb7420242ac1c0002' target='blank'>https://web.lab-ml.com/run?run_uuid=c2c051c643fc11ebb7420242ac1c0002</a>\n",
              "  Prepare train_loader<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t643.04ms</span>\n",
              "Prepare trainer<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t672.73ms</span>\n",
              "Prepare training_loop...\n",
              "  Prepare loop_count<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t84.22ms</span>\n",
              "Prepare training_loop<span style=\"color: #00A250\">...[DONE]</span><span style=\"color: #208FFB\">\t255.67ms</span>\n",
              "<span style=\"color: #C5C1B4\">def train(</span><strong>P</strong><strong>P</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong><strong>~</strong>\n",
              "<span style=\"color: #C5C1B4\">def train(</span><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong><strong>e</strong>\n",
              "<span style=\"color: #C5C1B4\">def train(</span><strong>e</strong><strong>t</strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong><strong> </strong>\n",
              "<strong><span style=\"color: #DDB62B\">  43,008:  </span></strong>Sample:<span style=\"color: #C5C1B4\"> 100%</span><span style=\"color: #208FFB\">   436ms  </span>Train:<span style=\"color: #C5C1B4\">  48%</span><span style=\"color: #208FFB\"> 249,351ms  </span>Valid:<span style=\"color: #C5C1B4\">  36%</span><span style=\"color: #208FFB\"> 4,423ms  </span> loss.train: <strong> 2.65108</strong> loss.valid: <span style=\"color: #C5C1B4\"> 2.79846</span>  <span style=\"color: #208FFB\">254,211ms</span><span style=\"color: #D160C4\">  0:02m/  2:13m  </span></pre>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUJL3TYxQzro"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}